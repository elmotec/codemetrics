{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code metrics analysis\n",
    "\n",
    "This notebooks demonstrates how to use __[codemetrics](https://github.com/elmotec/codemetrics)__ to gain insight on a code base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib as pl\n",
    "import datetime as dt\n",
    "import textwrap\n",
    "import json\n",
    "import pathlib as pth\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from altair.vega.v5 import Vega\n",
    "from tqdm import tqdm\n",
    "\n",
    "import codemetrics as cm\n",
    "import codemetrics.vega\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = cm.log\n",
    "logging.basicConfig(format=\"%(relativeCreated)6d %(level)s %(message)s\")\n",
    "log.setLevel(logging.WARNING) \n",
    "log.info(\"logging enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Sets up a few useful things:\n",
    "    - define a few useful variables like `year_ago` \n",
    "    - change directory to the location of the project being analyzed.\n",
    "    - joblib.Memory to cache some outputs and clearing out the cache when we execute this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful variables\n",
    "year_ago = dt.datetime.now(tz=dt.timezone.utc) - dt.timedelta(365)\n",
    "\n",
    "# Change current directory to the project under being analyzed.\n",
    "pandas = cm.GitProject(pl.Path().absolute() / '..' / '..'/  'pandas')\n",
    "\n",
    "# Sets up caching and wipes out cache if any.\n",
    "disk = joblib.Memory(location=os.getenv('TEMP'), verbose=0)\n",
    "get_cloc = disk.cache(cm.get_cloc)\n",
    "get_cloc.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lines of code (loc)\n",
    "\n",
    "Leverage cloc to count the lines of code and infer some basic information about the languages used in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloc_program = 'cloc.exe'\n",
    "loc = cm.get_cloc(pandas, cloc_program=cloc_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_sum = loc.groupby('language').sum().reset_index().melt(id_vars=['language']).rename(columns={'variable': 'type', 'value': 'lines'})\n",
    "alt.Chart(loc_sum).mark_bar().encode(\n",
    "    x=alt.X('lines:Q'),\n",
    "    y=alt.Y('language:N', sort=alt.EncodingSortField(field='lines', op='sum', order='descending')),\n",
    "    color=alt.Color('type:N', scale=alt.Scale(scheme='accent')), \n",
    "    tooltip=['lines:Q', 'type:O'],\n",
    ").properties(title='Lines of code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve git log data\n",
    "\n",
    "Now that we know what the code base looks like today, we turn our attention to history and build a data frame of the git log history for the past year. \n",
    "\n",
    "We then calculate the age of each file and generate a graph of recent changes as well as a circle visualization of the code base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pandas.get_log(path='.', after=year_ago)\n",
    "log['issue'] = log['message'].str.extract(r'\\(#(\\d+)\\)')\n",
    "log = pd.merge(log, loc[['path']], left_on='path', right_on='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = cm.get_ages(log).merge(loc)\n",
    "ages['last_change'] = ages['age'].apply(lambda a: pd.to_datetime('today') - dt.timedelta(a))\n",
    "ages['age_in_week'] = ages['age'].apply(lambda d: int(d / 7))\n",
    "\n",
    "width = 1000\n",
    "weeks = list(range(int(400 / 7)))\n",
    "chart = alt.Chart(ages).encode(color='language')\n",
    "top = chart.mark_bar().\\\n",
    "    encode(x=alt.X('age_agg:O', sort='ascending', title='age in weeks', scale=alt.Scale(domain=weeks)),\n",
    "           y=alt.Y('count(path):Q', title='Number of files'),\n",
    "           color=alt.Color('language', scale=alt.Scale(scheme='tableau10')),\n",
    "           tooltip=['count(path)', 'language']\n",
    "          ).\\\n",
    "    transform_calculate(age_agg='floor(datum.age / 7)').\\\n",
    "    properties(width=width)\n",
    "bottom = chart.mark_tick(size=60, thickness=2, opacity=.3).\\\n",
    "    encode(x=alt.X('age:Q', title='age in days'),\n",
    "           tooltip='path').properties(width=width)\n",
    "alt.vconcat(top, bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_ages = ages.query(\"path.str.endswith('.py') | path.str.endswith('.c')\")\n",
    "desc = cm.vega.vis_ages(code_ages, height=500, width=500)\n",
    "Vega(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity\n",
    "\n",
    "On to complexity calculation. Here we calculate the complexity of the current code base, file by file,\n",
    "function by function so it could take a little long. We run it on .py files only and we leverage tqdm to\n",
    "show a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Python file with the most recent revision\n",
    "python_df = (log[['path', 'date']]\n",
    "             .groupby('path', as_index=False)\n",
    "             .max()\n",
    "             .query(\"path.str.endswith('.py')\")\n",
    "             .merge(log[['path', 'date', 'revision']])\n",
    "             .assign(path=lambda x: x[\"path\"].astype(\"string\"))\n",
    "            )\n",
    "# Progress bar for pandas\n",
    "tqdm.pandas(desc=\"calculating\")\n",
    "# Calculates complexity on python files.\n",
    "complexity = (python_df[['revision', 'path']]\n",
    "              .groupby(['revision', 'path'])\n",
    "              .progress_apply(cm.get_complexity, project=pandas)\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates 80% percentile of complexity for each file\n",
    "path_complexity = (complexity\n",
    "                   .reset_index()[['path', 'cyclomatic_complexity', 'token_count']]\n",
    "                   .groupby('path').quantile(0.8)\n",
    "                   .sort_values(by='cyclomatic_complexity', ascending=False)\n",
    "                   .reset_index()\n",
    "                   .rename(columns={'cyclomatic_complexity': 'complexity'})\n",
    "                  )\n",
    "# Merge to lines of code. \n",
    "loc_cc = pd.merge(loc, path_complexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hot spots\n",
    "\n",
    "Hot spots are files that exhibit high complexity __and__ changed a lot recently. This is typically where you will find bugs.\n",
    "\n",
    "The graph below will show files harboring complexity as large circle while an increased number of change will make the color trend from yellow to more red shades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hspots = cm.get_hot_spots(log.head(1), loc_cc.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hspots = cm.get_hot_spots(log, loc_cc.assign(path=lambda x: x['path'].astype('string'))) \n",
    "hspots.query(\"language == 'Python'\").sort_values(by=['changes', 'complexity'], ascending=False).head()\n",
    "desc = cm.vega.vis_hot_spots(hspots, width=500, height=500, size_column='complexity')\n",
    "Vega(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-changes or inter-file coupling\n",
    "\n",
    "Co-changes builds on the idea that files or functions that change together imply a hidden dependency and may need refactoring.\n",
    "\n",
    "We calculate how often each file change in relation to the other and display high level of coupling. Again, we focus on the files that have changed a lot recently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_changes = cm.get_co_changes(log, by='path', on='issue').\\\n",
    "    query(\"(coupling > .6) & (changes > 20)\").\\\n",
    "    sort_values(by=['changes', 'cochanges'], ascending=False)\n",
    "co_changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File level analysis\n",
    "\n",
    "It can also be useful to dive into the complexity history of one particular file or function. Let's consider the following file and calculate historical complexity of each function in the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'pandas/core/frame.py'\n",
    "func_df = log[log['path'] == path][['date', 'revision', 'path']]\n",
    "func_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_cplx_df = func_df.groupby(['revision', 'path']).progress_apply(cm.get_complexity, project=pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_cpx_df = pd.merge(func_df, func_cplx_df.reset_index(), on=['revision', 'path'])\n",
    "top_cpx_func_df = func_cpx_df.groupby('name')[['cyclomatic_complexity']].mean().nlargest(8, 'cyclomatic_complexity')\n",
    "filt_func_cpx_df = func_cpx_df[func_cpx_df['name'].isin(set(top_cpx_func_df.index))]\n",
    "filt_func_cpx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(filt_func_cpx_df).\\\n",
    "    mark_line().encode(\n",
    "        x='date:T',\n",
    "        y='cyclomatic_complexity:Q',\n",
    "        color='name:N',\n",
    "        tooltip=['name', 'revision']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be continued..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_func_cpx_df.query(\"name == '_sanitize_column' and cyclomatic_complexity <= 11\").sort_values(by=\"date\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
